df2$x1 <- as.numeric(df2$x1)
df2$x2 <- as.numeric(df2$x2)
lda.orig <- lda(y~., data=df2, CV=TRUE)
table(df2$y, lda.orig$class)
LogLoss(lda.orig$posterior[,2], as.numeric(df2$y))
car93 <- read.csv('car93.csv')
log.data2 <- cbind(y = car93$Type, x1 = pca.car$x[,1], x2 = pca.car$x[,2])
df2 <- data.frame(log.data2)
df2$y <- factor(df2$y)
df2$x1 <- as.numeric(df2$x1)
df2$x2 <- as.numeric(df2$x2)
lda.orig <- lda(y~., data=df2, CV=TRUE)
table(df2$y, lda.orig$class)
LogLoss(lda.orig$posterior[,2], as.numeric(df2$y)-1)
?fit.contrast
F1 <- 5; df.t <- 2; df.r <- 4
1-pf(F1, df.t, df.r)
1-pf(5.003, 3, 15)
F1 <- 5; df.t <- 2; df.r <- 4
1-pf(F1, df.t, df.r)
library(ggplot2)
ggplot(alc.data, aes(group, score)) + geom_point()
alc <- read.csv('AlcData.csv', header=TRUE)
head(alc)
alc.data = stack(alc, na.rm=TRUE)
colnames(alc.data) = c("score", "group")
head(alc.data)
summary(aov(score ~ group, data = alc.data))
library(gmodels)
mod0 <- lm(score ~ group, data = alc.data)
fit.contrast(mod0, 'group', c(1,-1/3,-1/3,-1/3))
library(ggplot2)
ggplot(alc.data, aes(group, score)) + geom_point()
qqnorm(alc.data$score)
qqline(alc.data$score)
library(ggplot2)
ggplot(alc.data, aes(group, score)) + geom_boxplot()
for(i in 1:nrow(df)){
train <- df[-i,]
test <- df[i,]
log.fit <- glm(y~., family = 'binomial', data=train)
log.result[i] <- predict(log.fit, newdata=test, type = 'response')
results <- ifelse(log.result > 0.5, 1, 0)
}
LogLoss(log.result, as.numeric(df$y)-1)
table(df$y, results)
LogLoss(log.fit$fitted.values, as.numeric(df$y)-1)
library(tidyverse)
library(dplyr)
car93 <- read.csv('car93.csv')
car.num <- car93 %>% select_if(is.numeric)
pca.car <- prcomp(car.num, scale. = TRUE)
summary(pca.car)
biplot(pca.car)
library(glmnet)
library(gclus)
library(MLmetrics)
#car93[car93$Type != 'Small',]$Type <- 'not small'
car93[car93$Type != 'Small',]$Type <- 0
car93[car93$Type == 'Small',]$Type <- 1
log.data <- cbind(y = car93$Type, x1 = pca.car$x[,1], x2 = pca.car$x[,2])
df <- data.frame(log.data)
df$y <- factor(df$y)
df$x1 <- as.numeric(df$x1)
df$x2 <- as.numeric(df$x2)
head(df)
for(i in 1:nrow(df)){
train <- df[-i,]
test <- df[i,]
log.fit <- glm(y~., family = 'binomial', data=train)
log.result[i] <- predict(log.fit, newdata=test, type = 'response')
results <- ifelse(log.result > 0.5, 1, 0)
}
LogLoss(log.result, as.numeric(df$y)-1)
table(df$y, results)
LogLoss(log.fit$fitted.values, as.numeric(df$y)-1)
for(i in 1:nrow(df)){
train <- df[-i,]
test <- df[i,]
log.fit <- glm(y~., family = 'binomial', data=train)
log.result[i] <- predict(log.fit, newdata=test, type = 'response')
results <- ifelse(log.result > 0.5, 1, 0)
}
LogLoss(log.result, as.numeric(df$y)-1)
table(df$y, results)
library(MASS)
lda.fit <- lda(y~., data=df, CV=TRUE)
table(df$y, lda.fit$class)
LogLoss(lda.fit$posterior[,2], as.numeric(df$y)-1)
car93 <- read.csv('car93.csv')
log.data2 <- cbind(y = car93$Type, x1 = pca.car$x[,1], x2 = pca.car$x[,2])
df2 <- data.frame(log.data2)
df2$y <- factor(df2$y)
df2$x1 <- as.numeric(df2$x1)
df2$x2 <- as.numeric(df2$x2)
lda.orig <- lda(y~., data=df2, CV=TRUE)
table(df2$y, lda.orig$class)
LogLoss(lda.orig$posterior[,2], as.numeric(df2$y)-1)
as.numeric(df2$y)-1
car93 <- read.csv('car93.csv')
log.data2 <- cbind(y = car93$Type, x1 = pca.car$x[,1], x2 = pca.car$x[,2])
df2 <- data.frame(log.data2)
df2$y <- factor(df2$y)
df2$x1 <- as.numeric(df2$x1)
df2$x2 <- as.numeric(df2$x2)
lda.orig <- lda(y~., data=df2, CV=TRUE)
table(df2$y, lda.orig$class)
LogLoss(lda.orig$posterior[,2], as.numeric(df2$y)-1)
library(tidyverse)
library(dplyr)
car93 <- read.csv('car93.csv')
car.num <- car93 %>% select_if(is.numeric)
pca.car <- prcomp(car.num, scale. = TRUE)
summary(pca.car)
biplot(pca.car)
library(glmnet)
library(gclus)
library(MLmetrics)
car93[car93$Type != 'Small',]$Type <- 'not small'
#car93[car93$Type != 'Small',]$Type <- 0
#car93[car93$Type == 'Small',]$Type <- 1
log.data <- cbind(y = car93$Type, x1 = pca.car$x[,1], x2 = pca.car$x[,2])
df <- data.frame(log.data)
df$y <- factor(df$y)
df$x1 <- as.numeric(df$x1)
df$x2 <- as.numeric(df$x2)
head(df)
for(i in 1:nrow(df)){
train <- df[-i,]
test <- df[i,]
log.fit <- glm(y~., family = 'binomial', data=train)
log.result[i] <- predict(log.fit, newdata=test, type = 'response')
results <- ifelse(log.result > 0.5, 1, 0)
}
LogLoss(log.result, as.numeric(df$y)-1)
table(df$y, results)
library(tidyverse)
library(dplyr)
car93 <- read.csv('car93.csv')
car.num <- car93 %>% select_if(is.numeric)
pca.car <- prcomp(car.num, scale. = TRUE)
summary(pca.car)
biplot(pca.car)
library(glmnet)
library(gclus)
library(MLmetrics)
car93[car93$Type != 'Small',]$Type <- 'not small'
#car93[car93$Type != 'Small',]$Type <- 0
#car93[car93$Type == 'Small',]$Type <- 1
log.data <- cbind(y = car93$Type, x1 = pca.car$x[,1], x2 = pca.car$x[,2])
df <- data.frame(log.data)
df$y <- factor(df$y)
df$x1 <- as.numeric(df$x1)
df$x2 <- as.numeric(df$x2)
head(df)
for(i in 1:nrow(df)){
train <- df[-i,]
test <- df[i,]
log.fit <- glm(y~., family = 'binomial', data=train)
log.result[i] <- predict(log.fit, newdata=test, type = 'response')
results <- ifelse(log.result > 0.5, 'Small', 'not small')
}
LogLoss(log.result, as.numeric(df$y)-1)
table(df$y, results)
library(MASS)
lda.fit <- lda(y~., data=df, CV=TRUE)
table(df$y, lda.fit$class)
LogLoss(lda.fit$posterior[,2], as.numeric(df$y)-1)
car93 <- read.csv('car93.csv')
log.data2 <- cbind(y = car93$Type, x1 = pca.car$x[,1], x2 = pca.car$x[,2])
df2 <- data.frame(log.data2)
df2$y <- factor(df2$y)
df2$x1 <- as.numeric(df2$x1)
df2$x2 <- as.numeric(df2$x2)
lda.orig <- lda(y~., data=df2, CV=TRUE)
table(df2$y, lda.orig$class)
LogLoss(lda.orig$posterior[,2], as.numeric(df2$y)-1)
qf(0.95,2,4)
F1 <- 5; df.t <- 2; df.r <- 4
1-pf(F1, df.t, df.r)
?fit.contrast
library(gmodels)
mod0 <- lm(score ~ group, data = alc.data)
fit.contrast(mod0, 'group', c(1,-1/3,-1/3,-1/3), df=TRUE)
fit.contrast(mod0, 'group', c(1,-1/3,-1/3,-1/3), df=TRUE, conf=0.975)
fit.contrast(mod0, 'group', c(1,-1/3,-1/3,-1/3), df=TRUE, conf=0.95)
fit.contrast(mod0, 'group', c(1,-1/3,-1/3,-1/3), df=TRUE, conf=0.975)
fit.contrast(mod0, 'group', c(1,-1/3,-1/3,-1/3), df=TRUE, conf=0.975)
qt(1-0.025)
qt(1-0.025)
qt(df=40, 1-0.025)
qt(df=40, 0.025)
qt(df=40, 1-0.025)
qt(df=40, 1-0.05)
1-pt(t1, df=40)
t1 <- qt(df=40, 1-0.05)
1-pt(t1, df=40)
qt(df=40, 1.474347e-05)
?qt
qt(df=40, 1.474347e-05)
fit.contrast(mod0, 'group', c(1,-1/3,-1/3,-1/3), df=TRUE, conf=0.975)
1.474347e-05/2
library(gmodels)
mod0 <- lm(score ~ group, data = alc.data)
fit.contrast(mod0, 'group', c(1,-1/3,-1/3,-1/3), df=TRUE)
res <- summary(mod0)
pt(coef(res)[,3], mod0$df, lower = FALSE)
mod0$df
coef(res)
coef(res)[,3]
coef(res)
qt(p=0.05, df=mod0$df, lower.tail=FALSE)
qt(p=0.05, df=mod0$df, lower.tail=TRUE)
qt(p=0.05, df=mod0$df, lower.tail=TRUE)
?nnet
set.seed(4521)
nnfish <- nnet(V7~., data=sfish, size=5, hidden=1)
sum((predict(nnfish)-sfish$V7)^2)/nrow(sfish)
mean((predict(nnfish)-sfish$V7)^2)
set.seed(4521)
nnfish2 <- nnet(train[,1:6], train[,7], size=5)
set.seed(4521)
nnfish2 <- nnet(x=train[,1:6], y=train[,7], size=5)
train
train
fishdata <- read.csv('fish_toxicity.csv', header = FALSE, sep = ';')
fishdata
library(nnet)
sfish <- apply(fishdata, 2, function(v) (v-min(v))/(max(v)-min(v)))
sfish <- data.frame(sfish)
sfish
set.seed(4521)
nnfish <- nnet(V7~., data=sfish, size=5)
sum((predict(nnfish)-sfish$V7)^2)/nrow(sfish)
mean((predict(nnfish)-sfish$V7)^2)
set.seed(217, sample.kind="Rounding")
ind <- sample(1:nrow(sfish), 454)
train <- sfish[ind,]
test <- sfish[-ind,]
train
tail(train)
scores <- data.frame(car93, pca.car$x[,1:2])
scores
library(ggplot2)
scores <- data.frame(car93, pca.car$x[,1:2])
ggplot(scores, aes(x=PC1, y=PC2, color=Type)) + geom_point(size =2) + labs(title="Plotting Customer Data against PC1 and PC2")
library(ggplot2)
scores1 <- data.frame(df, pca.car$x[,1:2])
ggplot(scores1, aes(x=PC1, y=PC2, color=Type)) + geom_point(size =2)
library(tidyverse)
library(dplyr)
car93 <- read.csv('car93.csv')
car.num <- car93 %>% select_if(is.numeric)
pca.car <- prcomp(car.num, scale. = TRUE)
summary(pca.car)
biplot(pca.car)
library(ggplot2)
scores1 <- data.frame(df, pca.car$x[,1:2])
ggplot(scores1, aes(x=PC1, y=PC2, color=y)) + geom_point(size =2)
library(ggplot2)
scores1 <- data.frame(df, pca.car$x[,1:2])
ggplot(scores1, aes(x=PC1, y=PC2, color=y)) + geom_point(size =3)
library(ggplot2)
scores2 <- data.frame(car93, pca.car$x[,1:2])
ggplot(scores2, aes(x=PC1, y=PC2, color=Type)) + geom_point(size =3)
library(ggplot2)
scores1 <- data.frame(df, pca.car$x[,1:2])
ggplot(scores1, aes(x=PC1, y=PC2, color=y)) + geom_point(size =3) + labs(title="A")
scores2 <- data.frame(car93, pca.car$x[,1:2])
ggplot(scores2, aes(x=PC1, y=PC2, color=Type)) + geom_point(size =3)+ labs(title="B")
library(tidyverse)
library(dplyr)
car93 <- read.csv('car93.csv')
car.num <- car93 %>% select_if(is.numeric)
pca.car <- prcomp(car.num, scale. = TRUE)
summary(pca.car)
biplot(pca.car)
round(pca.car$rotation[,1:2], 2)
(pca.car$sdev)^2
plot(pca.car, type = 'lines')
library(glmnet)
library(gclus)
library(MLmetrics)
car93[car93$Type != 'Small',]$Type <- 'not small'
log.data <- cbind(y = car93$Type, x1 = pca.car$x[,1], x2 = pca.car$x[,2])
df <- data.frame(log.data)
df$y <- factor(df$y)
df$x1 <- as.numeric(df$x1)
df$x2 <- as.numeric(df$x2)
head(df)
for(i in 1:nrow(df)){
train <- df[-i,]
test <- df[i,]
log.fit <- glm(y~., family = 'binomial', data=train)
log.result[i] <- predict(log.fit, newdata=test, type = 'response')
results <- ifelse(log.result > 0.5, 'Small', 'not small')
}
LogLoss(log.result, as.numeric(df$y)-1)
table(df$y, results)
library(MASS)
lda.fit <- lda(y~., data=df, CV=TRUE)
table(df$y, lda.fit$class)
LogLoss(lda.fit$posterior[,2], as.numeric(df$y)-1)
car93 <- read.csv('car93.csv')
log.data2 <- cbind(y = car93$Type, x1 = pca.car$x[,1], x2 = pca.car$x[,2])
df2 <- data.frame(log.data2)
df2$y <- factor(df2$y)
df2$x1 <- as.numeric(df2$x1)
df2$x2 <- as.numeric(df2$x2)
lda.orig <- lda(y~., data=df2, CV=TRUE)
table(df2$y, lda.orig$class)
LogLoss(lda.orig$posterior[,2], as.numeric(df2$y)-1)
library(ggplot2)
scores1 <- data.frame(df, pca.car$x[,1:2])
ggplot(scores1, aes(x=PC1, y=PC2, color=y))+ geom_point(size =3)+ labs(title="A")
scores2 <- data.frame(car93, pca.car$x[,1:2])
ggplot(scores2, aes(x=PC1, y=PC2, color=Type))+ geom_point(size =3)+ labs(title="B")
fishdata <- read.csv('fish_toxicity.csv', header = FALSE, sep = ';')
fishdata
library(nnet)
sfish <- apply(fishdata, 2, function(v) (v-min(v))/(max(v)-min(v)))
sfish <- data.frame(sfish)
sfish
set.seed(4521)
nnfish <- nnet(V7~., data=sfish, size=5)
sum((predict(nnfish)-sfish$V7)^2)/nrow(sfish)
mean((predict(nnfish)-sfish$V7)^2)
set.seed(217, sample.kind="Rounding")
ind <- sample(1:nrow(sfish), 454)
train <- sfish[ind,]
test <- sfish[-ind,]
tail(train)
set.seed(4521)
nnfish2 <- nnet(V7~., data=train, size=5)
sum((predict(nnfish2, newdata=test)-test$V7)^2)/nrow(test)
mean((predict(nnfish2, newdata=test)-test$V7)^2)
pr.nn <- predict(nnfish2, newdata=test)
pre.nn <- pr.nn*(max(fishdata$V7) - min(fishdata$V7)) + min(fishdata$V7)
test.r <- (test$V7)*(max(fishdata$V7) - min(fishdata$V7)) + min(fishdata$V7)
mean((test.r - pre.nn)^2)
sum((test.r - pre.nn)^2)/nrow(test)
set.seed(4521)
lmfish <- lm(V7~., data = train)
mean((predict(lmfish, newdata=test)-test$V7)^2)
sum((predict(lmfish, newdata=test) - test$V7)^2)/nrow(test)
set.seed(4521)
nnfish3.l <- nnet(V7~., data=train, size=5, linout=TRUE)
sum((predict(nnfish3.l, newdata=test)-test$V7)^2)/nrow(test)
set.seed(4521)
nnfish4 <- nnet(V7~., data=train, size=10)
sum((predict(nnfish4, newdata=test)-test$V7)^2)/nrow(test)
set.seed(4521)
nnfish5 <- nnet(V7~., data=train, size=30)
sum((predict(nnfish5, newdata=test)-test$V7)^2)/nrow(test)
set.seed(4521)
nnfish5.l <- nnet(V7~., data=train, size=30, linout=TRUE)
sum((predict(nnfish5.l, newdata=test)-test$V7)^2)/nrow(test)
pr.nn2 <- predict(nnfish5, newdata=test)
pre.nn2 <- pr.nn2*(max(fishdata$V7) - min(fishdata$V7)) + min(fishdata$V7)
sum((test.r - pre.nn2)^2)/nrow(test)
for(i in 1:nrow(df)){
train <- df[-i,]
test <- df[i,]
log.fit <- glm(y~., family = 'binomial', data=train)
log.result <- predict(log.fit, newdata=test, type = 'response')
results <- ifelse(log.result > 0.5, 'Small', 'not small')
}
LogLoss(log.result, as.numeric(df$y)-1)
table(df$y, results)
set.seed(4521)
nnfish2 <- nnet(V7~., data=train, size=5)
library(nnet)
sfish <- apply(fishdata, 2, function(v) (v-min(v))/(max(v)-min(v)))
sfish <- data.frame(sfish)
head(sfish)
set.seed(4521)
nnfish <- nnet(V7~., data=sfish, size=5)
sum((predict(nnfish)-sfish$V7)^2)/nrow(sfish)
mean((predict(nnfish)-sfish$V7)^2)
set.seed(217, sample.kind="Rounding")
ind <- sample(1:nrow(sfish), 454)
train <- sfish[ind,]
test <- sfish[-ind,]
set.seed(4521)
nnfish2 <- nnet(V7~., data=train, size=5)
sum((predict(nnfish2, newdata=test[,-7])-test$V7)^2)/nrow(test)
mean((predict(nnfish2, newdata=test[,-7])-test$V7)^2)
pr.nn <- predict(nnfish2, newdata=test)
pre.nn <- pr.nn*(max(fishdata$V7) - min(fishdata$V7)) + min(fishdata$V7)
test.r <- (test$V7)*(max(fishdata$V7) - min(fishdata$V7)) + min(fishdata$V7)
mean((test.r - pre.nn)^2)
sum((test.r - pre.nn)^2)/nrow(test)
set.seed(4521)
lmfish <- lm(V7~., data = train)
mean((predict(lmfish, newdata=test[,-7])-test$V7)^2)
sum((predict(lmfish, newdata=test[,-7]) - test$V7)^2)/nrow(test)
set.seed(4521)
nnfish3.l <- nnet(V7~., data=train, size=5, linout=TRUE)
sum((predict(nnfish3.l, newdata=test[,-7])-test$V7)^2)/nrow(test)
set.seed(4521)
nnfish4 <- nnet(V7~., data=train, size=10)
sum((predict(nnfish4, newdata=test[,-7])-test$V7)^2)/nrow(test)
set.seed(4521)
nnfish5 <- nnet(V7~., data=train, size=30)
sum((predict(nnfish5, newdata=test[,-7])-test$V7)^2)/nrow(test)
set.seed(4521)
nnfish5.l <- nnet(V7~., data=train, size=30, linout=TRUE)
sum((predict(nnfish5.l, newdata=test[,-7])-test$V7)^2)/nrow(test)
pr.nn2 <- predict(nnfish5, newdata=test[,-7])
pre.nn2 <- pr.nn2*(max(fishdata$V7) - min(fishdata$V7)) + min(fishdata$V7)
sum((test.r - pre.nn2)^2)/nrow(test)
pr.nn <- predict(nnfish2, newdata=test[,-7])
pre.nn <- pr.nn*(max(fishdata$V7) - min(fishdata$V7)) + min(fishdata$V7)
test.r <- (test$V7)*(max(fishdata$V7) - min(fishdata$V7)) + min(fishdata$V7)
mean((test.r - pre.nn)^2)
sum((test.r - pre.nn)^2)/nrow(test)
pr.nn <- predict(nnfish2, newdata=test[,-7])
pre.nn <- pr.nn*(max(fishdata$V7) - min(fishdata$V7)) + min(fishdata$V7)
test.r <- (test$V7)*(max(fishdata$V7) - min(fishdata$V7)) + min(fishdata$V7)
mean((test.r - pre.nn)^2)
sum((test.r - pre.nn)^2)/nrow(test)
getwd()
setwd('C:/MDS/DATA534/Project/R-vengers/R.vengers')
devtools::document()
car93 <- read.csv('car93.csv')
log.data2 <- cbind(y = car93$Type, x1 = pca.car$x[,1], x2 = pca.car$x[,2])
df2 <- data.frame(log.data2)
df2$y <- factor(df2$y)
df2$x1 <- as.numeric(df2$x1)
df2$x2 <- as.numeric(df2$x2)
lda.orig <- lda(y~., data=df2, CV=TRUE)
table(df2$y, lda.orig$class)
LogLoss(lda.orig$posterior, as.numeric(df2$y)-1)
car93 <- read.csv('car93.csv')
log.data2 <- cbind(y = car93$Type, x1 = pca.car$x[,1], x2 = pca.car$x[,2])
df2 <- data.frame(log.data2)
df2$y <- factor(df2$y)
df2$x1 <- as.numeric(df2$x1)
df2$x2 <- as.numeric(df2$x2)
lda.orig <- lda(y~., data=df2, CV=TRUE)
table(df2$y, lda.orig$class)
LogLoss(lda.orig$posterior, as.numeric(df2$y))
car93 <- read.csv('car93.csv')
log.data2 <- cbind(y = car93$Type, x1 = pca.car$x[,1], x2 = pca.car$x[,2])
df2 <- data.frame(log.data2)
df2$y <- factor(df2$y)
df2$x1 <- as.numeric(df2$x1)
df2$x2 <- as.numeric(df2$x2)
lda.orig <- lda(y~., data=df2, CV=TRUE)
table(df2$y, lda.orig$class)
MultiLogLoss(lda.orig$posterior, as.numeric(df2$y))
log.result <- NULL
for(i in 1:nrow(df)){
train <- df[-i,]
test <- df[i,]
log.fit <- glm(y~., family = 'binomial', data=train)
log.result[i] <- predict(log.fit, newdata=test, type = 'response')
results <- ifelse(log.result > 0.5, 'Small', 'not small')
}
LogLoss(log.result, as.numeric(df$y)-1)
table(df$y, results)
pca.car$x
pca.car$x[,1]
?prcomp
nrow(car93)
pt(0.95, 118)
qt(0.95, 118)
qt(0.05, 118)
qt(0.95, 118, lower.tail = FALSE)
?qt
qt(0.95,118)
pt(1.98,118)
qt(0.95,118)
pt(4.282,118)
2*pt(4.282,118)
2*pt(-4.282,118)
2*qt(0.95,118)
qt(p=0.05, df=mod0$df, lower.tail=FALSE)
qt(0.05/2,118)
abs(qt(0.05/2, 118))
qf(0.05, df1 = 2, df2 = 48, lower.tail = FALSE)
a <- c(6.5,14.1,9.9,13.4,6.6,8.2)
mean(a)
var(a)
b <- c(10,14.5,13.2,12.9,10,7.4)
mean(b)
var(b)
c <- c(5,14.4,10.5,12.1,6.8,6.9)
mean(c)
var(c)
d <- c(6.8,15,12.2,15.6,8.8,11.4)
mean(d)
var(d)
e <- cbind(a,b,c,d)
var(e)
e
typeof(e)
f <- data.frame(e)
f
var(f)
f[,1]
f[1]
f[1,]
mean(f[1,])
1-pf(5,3,15)
fit.contrast(aov(score ~ group, data = alc.data), 'group', c(1,-1/3,-1/3,-1/3))
fit.contrast(aov(score ~ group, data = alc.data), 'group', c(-1,-1,-1,3))
fit.contrast(mod0, 'group', c(-1,-1,-1,3))
pt(2.198717, 40, lower.tail = FALSE)
pt(-4.931104, 40, lower.tail = FALSE)
pt(4.931104, 40, lower.tail = FALSE)
qt(p=0.05, df=mod0$df, lower.tail=FALSE)
